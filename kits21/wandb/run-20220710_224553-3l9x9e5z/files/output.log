INFO: Starting training:
        Epochs:          {epochs}
        Batch size:      {batch_size}
        Learning rate:   {learning_rate}
        Training size:   {n_train}
        Validation size: {n_val}
        Checkpoints:     {save_checkpoint}
        Device:          {device.type}
        Images scaling:  {img_scale}
        Mixed Precision: {amp}
Epoch 1/1000:   0%|          | 0/10790 [00:00<?, ?img/s]C:\Users\OUR\anaconda3\envs\pytorch=3.10\lib\site-packages\torch\autocast_mode.py:162: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling
  warnings.warn('User provided device_type of \'cuda\', but CUDA is not available. Disabling')
llllll000000000000
tensor([0, 1, 2, 3])
Epoch 1/1000:   0%|          | 8/10790 [00:31<11:55:49,  3.98s/img, loss (batch)=1.44]
llllll000000000000

Epoch 1/1000:   0%|          | 16/10790 [00:48<8:40:15,  2.90s/img, loss (batch)=1.39]
llllll000000000000

Epoch 1/1000:   0%|          | 24/10790 [01:03<7:11:15,  2.40s/img, loss (batch)=1.34]
llllll000000000000

Epoch 1/1000:   0%|          | 32/10790 [01:17<6:22:04,  2.13s/img, loss (batch)=1.31]
llllll000000000000

Epoch 1/1000:   0%|          | 40/10790 [01:30<5:52:28,  1.97s/img, loss (batch)=1.28]
llllll000000000000

Epoch 1/1000:   0%|          | 48/10790 [01:44<5:34:42,  1.87s/img, loss (batch)=1.24]
llllll000000000000

Epoch 1/1000:   1%|          | 56/10790 [01:57<5:23:10,  1.81s/img, loss (batch)=1.2]
llllll000000000000

Epoch 1/1000:   1%|          | 64/10790 [02:10<5:15:15,  1.76s/img, loss (batch)=1.18]
llllll000000000000

Epoch 1/1000:   1%|          | 72/10790 [02:24<5:10:55,  1.74s/img, loss (batch)=1.14]
llllll000000000000

Epoch 1/1000:   1%|          | 80/10790 [02:38<5:08:59,  1.73s/img, loss (batch)=1.1]
llllll000000000000

Epoch 1/1000:   1%|          | 88/10790 [02:51<5:05:56,  1.72s/img, loss (batch)=1.08]
llllll000000000000

Epoch 1/1000:   1%|          | 96/10790 [03:04<5:03:37,  1.70s/img, loss (batch)=1.05]
llllll000000000000

Epoch 1/1000:   1%|          | 104/10790 [03:18<5:03:14,  1.70s/img, loss (batch)=1.02]
llllll000000000000

Epoch 1/1000:   1%|          | 112/10790 [03:32<5:05:08,  1.71s/img, loss (batch)=1.01]
llllll000000000000

Epoch 1/1000:   1%|          | 120/10790 [03:46<5:05:49,  1.72s/img, loss (batch)=0.984]
llllll000000000000

Epoch 1/1000:   1%|          | 128/10790 [03:59<5:04:48,  1.72s/img, loss (batch)=0.954]
llllll000000000000

Epoch 1/1000:   1%|▏         | 136/10790 [04:13<5:03:31,  1.71s/img, loss (batch)=0.943]
llllll000000000000

Epoch 1/1000:   1%|▏         | 144/10790 [04:27<5:02:51,  1.71s/img, loss (batch)=0.918]
llllll000000000000

Epoch 1/1000:   1%|▏         | 152/10790 [04:40<5:03:02,  1.71s/img, loss (batch)=0.909]
llllll000000000000

Epoch 1/1000:   1%|▏         | 160/10790 [04:54<5:03:35,  1.71s/img, loss (batch)=0.883]
llllll000000000000

Epoch 1/1000:   2%|▏         | 168/10790 [05:08<5:02:20,  1.71s/img, loss (batch)=0.863]
llllll000000000000

Epoch 1/1000:   2%|▏         | 176/10790 [05:21<5:01:30,  1.70s/img, loss (batch)=0.865]
llllll000000000000

Epoch 1/1000:   2%|▏         | 184/10790 [05:35<5:00:02,  1.70s/img, loss (batch)=0.841]
llllll000000000000

Epoch 1/1000:   2%|▏         | 192/10790 [05:48<5:00:44,  1.70s/img, loss (batch)=0.819]
llllll000000000000

Epoch 1/1000:   2%|▏         | 200/10790 [06:02<5:00:11,  1.70s/img, loss (batch)=0.82]
llllll000000000000

Epoch 1/1000:   2%|▏         | 208/10790 [06:16<4:59:42,  1.70s/img, loss (batch)=0.804]
llllll000000000000

Epoch 1/1000:   2%|▏         | 216/10790 [06:29<4:59:16,  1.70s/img, loss (batch)=0.789]
llllll000000000000

Epoch 1/1000:   2%|▏         | 224/10790 [06:44<5:06:57,  1.74s/img, loss (batch)=0.776]
llllll000000000000

Epoch 1/1000:   2%|▏         | 232/10790 [06:58<5:08:23,  1.75s/img, loss (batch)=0.755]
llllll000000000000

Epoch 1/1000:   2%|▏         | 240/10790 [07:12<5:05:25,  1.74s/img, loss (batch)=0.76]
llllll000000000000

Epoch 1/1000:   2%|▏         | 248/10790 [07:25<5:04:06,  1.73s/img, loss (batch)=0.745]
llllll000000000000

Epoch 1/1000:   2%|▏         | 256/10790 [07:39<5:02:59,  1.73s/img, loss (batch)=0.733]
llllll000000000000

Epoch 1/1000:   2%|▏         | 264/10790 [07:55<5:18:36,  1.82s/img, loss (batch)=0.72]
llllll000000000000

Epoch 1/1000:   3%|▎         | 272/10790 [08:13<5:35:56,  1.92s/img, loss (batch)=0.719]
llllll000000000000
Epoch 1/1000:   3%|▎         | 272/10790 [08:29<5:28:32,  1.87s/img, loss (batch)=0.719]
Traceback (most recent call last):
  File "C:\Users\OUR\anaconda3\envs\pytorch=3.10\lib\multiprocessing\queues.py", line 247, in _feed
    send_bytes(obj)
  File "C:\Users\OUR\anaconda3\envs\pytorch=3.10\lib\multiprocessing\connection.py", line 205, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "C:\Users\OUR\anaconda3\envs\pytorch=3.10\lib\multiprocessing\connection.py", line 285, in _send_bytes
    ov, err = _winapi.WriteFile(self._handle, buf, overlapped=True)
BrokenPipeError: [WinError 232] 管道正在被关闭。
INFO: Saved interrupt